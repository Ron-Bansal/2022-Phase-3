{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume tar.gz file to be extracted at project directory.\n",
    "# def unpickle(file):\n",
    "#     import pickle\n",
    "#     with open(file, 'rb') as fo:\n",
    "#         dict = pickle.load(fo, encoding='bytes')\n",
    "#     return dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# (X_train, y_train), (X_test, y_test) = dict.load_data()\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10 = keras.datasets.cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 32, 32, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \n",
    "\"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[int(y_train[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truck'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAf8UlEQVR4nO2da5DcZ5Xen9O3ud9HMxpJI40kS0K2bMtGKDZ2gCwBG0LKULuh4APxB2q9lYJKqGw+uNiqQKrygU0FKD4kpExwrdkQDFlgcQGbxWu8GBZsI2NblixblnWXZkbXUc+l733yodtVsvM+74wlTY/Y//OrUqnnfebt/9v/7tP/nvfpc465O4QQ//hJrfQChBCtQcEuREJQsAuREBTsQiQEBbsQCUHBLkRCyFzNZDO7F8DXAKQB/E93/1Ls93t6+3xoZDSolYsLdF61XAyOuxudk821Uy3XxrV0Nke1VCp8vGJhjs4plwpU81qNagb+2FLpNJ+XCr9/d3X30DltkfPhtSrVCgX+nAFhS7fudTqjWODnqhZZR8w+ZlK1ytdRr8fuj8/LZHg4ZTL8OXOEXwcxV7xOllFYKKBUKgdfPFcc7GaWBvDfAHwAwEkAvzWzx9z9ZTZnaGQUf/aV/x7UTr7yHD3W2SMHguO1Gl/+6Pp3UG395u1UG1i9nmrtHeHjHdz/azrn2KG9VKvM8jeJdOSx9Q70US3T3hkc333Xe+icG7byc1W8dIFq+/c9T7V6vRwcL1fCb9wA8PL+l6iWnzlHtVK5RLVKORxkF87zN6q5Bb7Gao0fa9WqQaoNDHZTreaz4WNV6BQUC+F3gr9/8mk652o+xu8GcMjdD7t7GcCjAO67ivsTQiwjVxPsawGcuOznk80xIcR1yLJv0JnZA2a2x8z2zOYvLffhhBCEqwn2UwDGL/t5XXPsTbj7Q+6+y9139fTyvzWFEMvL1QT7bwFsMbONZpYD8AkAj12bZQkhrjVXvBvv7lUz+yyAv0XDenvY3ffH5tRqNeQvhnd3h/r5TqavCtt1numlc8bWb+LrqPNtzlSd79LWF8L2T/HieTrHC3xnd+3wCNXWj99AtfEbNlBtzdp1wfERYnkCQDbbRrVqf3h3HwDG163m86rh3fhikdtrMxe5O3HuHHcFMhGbFRbejR8Y4o+5vYuv8VL+ItXa2nk41Z1bh9lMeC35SzN0TrkU3o135snhKn12d/8pgJ9ezX0IIVqDvkEnREJQsAuREBTsQiQEBbsQCUHBLkRCuKrd+LeNO1AJ217lErfDFhbCNs7EVv7t3Ln5earFkjEGhyNJJtnwe+OWLVvpnHffsYtqa0fDNhkA9PWtololw7PlOtvDNk4mkkFl1Uhm2zy3w0rkuQSAzo6wZTfQz+3GzZtupNqBA69SDcbXUSqFrdS+3gE6J5L4iEv5aao5wq9TIJ5Jd/Fi+LVaWOBJNywjLpYBqCu7EAlBwS5EQlCwC5EQFOxCJAQFuxAJoaW78V6vo0oSIazKd5jbch3B8UvneKmiodV8p3v9TTzJZGR8DdWybJs2Uj+oUuU7/69M8gSahcNn+X2m+K7vqy+9GBx/13a+0/2e3e+iWmx3Nx+pT3D82OngeC4bqQ2Y44lNw6u483L8xGv8PkmZrrkCd2vyef66ymR5bcDeXp40FKvXx8rrxerktbWFX4vGl6cruxBJQcEuREJQsAuREBTsQiQEBbsQCUHBLkRCaLn1VloIWx7dHdyS6R0MJ4XcfutOOmd80xaqzUYSP149fIJq+YWwfTI3M0PnnJ/h9trkFK9n1htJhEGKJ0j8+LvfD45nP87f1997591Uy2a5rbh6Nbcp4WH7auZiuPsJAPzued49JxOpk9fVwy27ai1sHZbnZuicdOQSGOv6UqtxS/T8BW7npRC27GLtpPr7wwlb6UibKV3ZhUgICnYhEoKCXYiEoGAXIiEo2IVICAp2IRLCVVlvZnYUwCyAGoCqu/OCawAsZWhrywa1SrqHzit0hBvZH8nzNj0v/OpZql04z+uqnTrNa4xl0+GUomyKZyeVSBskACgWuTa2ij81Z6aOUa2XZEPNzuTpnINHjvB1jA1TLZvlaxwbD7eGWkPGAeD4FLc9X32JayNj3KY8epxYXhX+nNXLXKtF6v+157g92JYJv+4BoFAM32dvL7cUM6RllEWu39fCZ/9n7sRUFUJcN+hjvBAJ4WqD3QH8zMyeM7MHrsWChBDLw9V+jL/b3U+Z2QiAx83sFXd/6vJfaL4JPAAA/QP8q4ZCiOXlqq7s7n6q+f8ZAD8EsDvwOw+5+y5339XVHd5oE0IsP1cc7GbWZWY9b9wG8EEA+67VwoQQ15ar+Rg/CuCH1qhwlwHwv939/8YmpFIZdHaOBrUzMzwT7dCJsO3y8n7+3pKK2EK1SKupwiwvRJgmFluhxG2tmVmuzUZaKx09eYBqXR3cpty2eVtYiFiA//DLv6faho0bqbZ1G297NTQUzspqa+fPS18vt65SVV7ccr7Er1mshVJhhmff1Wq8SGh7B7fQ5vL8PnsjmXlt7eFMtXI51hItnIFZr3Pb8IqD3d0PA7j1SucLIVqLrDchEoKCXYiEoGAXIiEo2IVICAp2IRJCSwtOptMZ9A+Gs6gOnThI500eDWdldWZ54cVL87yY41z+DNUsYl3MzIatspkCt2oyJMsPAIZHR6jW0RO2rgBg7QQ3QcaJjXPkxd/QOWnjtlylxrO8zp7jxTRvvnl7cPyGLZvonPFI9lr3HbdRbe8rx6lWKoYLmZaykaw3cJus7twinpoK97cDgFwbtxX7BtjrgNvAhUI447Pu/HHpyi5EQlCwC5EQFOxCJAQFuxAJQcEuREJo6W58qTSP118P14Z75fVDdN7pydeD47VI0kpPXxfVtm2ZoNqO7TuoNnk2vAN67Cxfx6rV4cQfANiwmSeZ9Azxnfrpi/x4fi7sXBw/xnesz0ZaVG2/kUr4wNbwjjsAzM+R3WK+uQ8vc1dg/9PcTdiybSfVRtf2B8effvap4DgATE3z5KVKhe/GFwt8/Rcjba86uvuD47Gd9XnSRi2WCKMruxAJQcEuREJQsAuREBTsQiQEBbsQCUHBLkRCaKn1Nj+Xx9NPPR5eyCipnQZg8/abg+MdkTY922/cQrVtW9dRrVYMJ5IAgKfCdtI8eEOcTDaciAEA6XQ/1SpVnjgxP3uBan3lsDVUrTmdc/wMTxpq7z7Fj9U7QLVNmyeC4x65vhRmwnXVAOCVZ16gmhf462DHPfcGx2++hSfkFPZw6+31Q0ep1tnJqyf39Q9RrdE97f8nn+fPS6kUPlcu600IoWAXIiEo2IVICAp2IRKCgl2IhKBgFyIhLGq9mdnDAD4C4Iy772iODQL4LoAJAEcBfNzduU/QpFKu4syJsE11263/gs5rawvXJhvkLhnG1vA6YhcirX9OHOK2VrketsNSxlO50hluhdSc19BDNda+KmwBAoDXwsfr7gvX/gOA83M8iy6V49mDded2XqObd2gSn9Hdzp+ziTXjVGtP83WkEK4bePMOnnHY399PtccKP6Pa1CQPgbUja6hWs3ANw2ykhVk+H7YHD2TDrdKApV3Z/wLAW83KBwE84e5bADzR/FkIcR2zaLA3+62/9XJ3H4BHmrcfAfDRa7ssIcS15kr/Zh9198nm7Sk0OroKIa5jrvrrsu7uZkb/aDKzBwA8AADZLK+hLoRYXq70yj5tZmMA0Pyfdl1w94fcfZe778pkWvpVfCHEZVxpsD8G4P7m7fsB/OjaLEcIsVwsxXr7DoD3ARg2s5MAvgDgSwC+Z2afBnAMwMeXcrBUKoPO7sGglo24ODMz4Q8ObYP9dM5ClXs8Rd6tCR0DPVRrqxu5Q269eeQMFys8y6u9g09MRdo11VPhed1D3PrJObcb0x08s81z3PusW/ixWY1beak0f8zZrhzVOrq5Vi2Fbdbzp6bpnKEu3obqvg/fQ7U9Lx6l2lykGGWxdDY4XiItngCgv6c/OJ5J8+dk0WB3908S6f2LzRVCXD/oG3RCJAQFuxAJQcEuREJQsAuREBTsQiSEln7LJZdrw9j6cLaRpfj7TrEYzvCZzvPl5/p5llelyq0ai3zLrzAXzqCqOF97JsMLR1bTXOvs5RlgI0MzVPMLYbumHOlRZnW+/o6ODqqlIlmHdQ8fr1bjNmUqGyn2meZrnJvnWYxGCjC2RV5v+bPcluvoDFvHAPCeO2+h2quvH6PavpenguNzeZ6NmCOFTOv1WAagECIRKNiFSAgKdiESgoJdiISgYBciISjYhUgILbXe3AC3sL1SiVhDC7Nha6UtYgvN5iOFI4u80ONCnts4WZL01tPFLbRVA9yq6R3kGWCr+vljq2X6qFZoC5/HCxt41lupNkk1RDLzatVI9h3JEKyleDaiRay3/kGefVevRdZIXld9ffz85ngtFszMzlDNK2FrFgB2bl9Ntf6e8Ovnxz/mxS3PTocLt1YjcaQruxAJQcEuREJQsAuREBTsQiQEBbsQCaG15V7dAbKDm6nznd2+8Hf+Md5HtscBvGNTP9W62/lObNr4+998fiY4Xly4ROd0dFWotm0L36kf37COaqnsBqrNzcyE729sjK/jCC0OjN5BcvIBDA7wZJ1MJpxsFMnTgEcSa9q7OqlWLUZ2oMnxsrHEK3C3Zmi4m2pzC9wVmJ8JJ7sAwNpV4Zp3H/2XH6Rz/vonfxccz2T4SdSVXYiEoGAXIiEo2IVICAp2IRKCgl2IhKBgFyIhLKX908MAPgLgjLvvaI59EcAfA3ijb83n3f2ni91XT1cn3nvnO4PaphtvpfNOnzoVHF+7hltXW7dsptrqVSNUSzu382ZJEkQpkixiKX5/3V08Eaa7m1te6Ry3DrPEwizMh1sMAcDtO7iVN7F1gmqVOrcVnVxHqnVuk3man6t0lr9UK0Xu59VJYkgqw69z1s7Xgci8UoWfj0ya1zaslWeC46siNt/d//RdwfHfPPsSnbOUK/tfALg3MP5Vd9/Z/LdooAshVpZFg93dnwLA80WFEL8XXM3f7J81s71m9rCZ8WRjIcR1wZUG+9cBbAawE8AkgC+zXzSzB8xsj5ntmZvnyf1CiOXlioLd3afdvebudQDfALA78rsPufsud9/V3cU3HIQQy8sVBbuZXZ5V8TEA+67NcoQQy8VSrLfvAHgfgGEzOwngCwDeZ2Y7ATiAowD+ZCkH6+zswDtveUdQu+k2br0VdoRttK4+nnXFK50BbtxaSUUsksGucB2xSPen6LtpnbQmAuK1xBCxeEqlcPunzTesp3M6ctwCLMzzjD5PRV4+FtY8Ut+t7lyrRZ6zWMujciF8Pmp1/phTmcjrI/KMzp7nFuyxIyeodtfdtwXHFyq8HmInsQcjTu/iwe7unwwMf3OxeUKI6wt9g06IhKBgFyIhKNiFSAgKdiESgoJdiITQ0oKTqVQKHSTTq7udt1Dq6iTLjBTXixU2tJj1FrN4PGyV1SvcQovZSRYpeliNmIcxe8VJwczufp4hWK3xY9XqkSqQpMUTADhqwfFUbPE1rtUy3BJ1RJ5sUuDU6uH1AUBb5DFna/w56yryeT4dtgAB4Ozh6eD4um286Oi5VPjbqLHTqyu7EAlBwS5EQlCwC5EQFOxCJAQFuxAJQcEuREJoqfWWTqfR0xe2gDySbbZQCtsnXuI9uUpkDgDMz81TrVzh80qlcLZZtcqtq0okQ60SOdZCpG/YwjzPhqqSTLqewT46p6evn2r9PcNUa8+F+7kBQI317rNIXzZwraeHF+A8f4afx2IhbFHV67y4koE/rnqNv+Z6e7h9vGH9KNUKC+HXo0eKc/b1hC3sdMTO1ZVdiISgYBciISjYhUgICnYhEoKCXYiE0NLd+JmZPP76sb8JarXsL+m8ixfDiQJzl87ROalIbkRsp356OnwsAKiR7JrBSDupgeEhqrWl+emfvzBDtYOvHaBafi68+zy+kbd4Sme5E9Lbw9e/cSOva7duPFyvb+OmtXTOYBvP4uhp52usR2oRIh1OTqnU+E53OtLiKR1Z4+hExLno5Tv1FQ8n5aS5KYDBwfBjzkSSw3RlFyIhKNiFSAgKdiESgoJdiISgYBciISjYhUgIS2n/NA7gWwBG0Wj39JC7f83MBgF8F8AEGi2gPu7uF2P3lZ+dw+NP/jqo9a/bRud5LWwnPf/rJ+mcDet4/a7hIW4nnTo5RbUqqVvWOdhP55RTPElm+iRvCfT+3XdSbectN1FtoVQMjqey/Kk+cvwY1Q6+9jrVXtr3PNX6+8JNPP/wjz5G59x101aq5SI9ttaNjVOtTKw3ixRri9UNrJDaegCQykTq2vXzRJ4OkrxST3OLmBmRkRKKS7qyVwH8qbvfCOAOAJ8xsxsBPAjgCXffAuCJ5s9CiOuURYPd3Sfd/XfN27MADgBYC+A+AI80f+0RAB9dpjUKIa4Bb+tvdjObAHAbgGcAjLr7ZFOaQuNjvhDiOmXJwW5m3QC+D+Bz7p6/XHN3B8LFu83sATPbY2Z7ymWe+C+EWF6WFOxmlkUj0L/t7j9oDk+b2VhTHwNwJjTX3R9y913uviuX498PFkIsL4sGuzXap3wTwAF3/8pl0mMA7m/evh/Aj6798oQQ14qlZL3dBeBTAF4ysxeaY58H8CUA3zOzTwM4BuDji93RwOAQ/tUn/3VQaxvZQuctzIbtsNdeepHOGVvN7ZhUpE5XRzvPoCrXwy18tu7gax8Y4xlxC8O8DtpHPvTPqdbZ00G1eWK9RTo1oUraWgFAsRq+PwA4c+YC1Y4dOR0c7+zk53fq5HmqHd3/GtVSRb7Gw1PBD5zY/cFddM6GiTVUi2XLpdojaWpZbssZqzVnfE7Ows9ZzHpbNNjd/VcA2F28f7H5QojrA32DToiEoGAXIiEo2IVICAp2IRKCgl2IhNDSgpNmQFsu/P5y8JV9dF7+Uth681h2UplnDM1F2j9ZxLtobwvnGlUWeDumS2f5GqeP86y3v/nbcGFOALg4Gzne3KXgeE8vt7z6BsItuQCgK1Io8eTJsL0GACPD4cKS7b3civzlT/hjvvDaXqrVyrzF1qGpcAHRk5EWWlu2cyu1r7eTawO8xVZHJ8966+sKv66y7bx4ZGdn+Hlx569fXdmFSAgKdiESgoJdiISgYBciISjYhUgICnYhEkJLrbd6tYLZ82Eb7ec/+gmdd2LqZHA8VQlnoQHA3r15qsVSg6pVntUEkmn0+I9/Tqfksty62nnb7VQr53qoli8tUO3w8XCW1/nzvD9cuciz3k5PHaXakaP8Pnfd9s7g+L/9zL+nc559+jdUq17iGXH5Ei+KUgjXVMHhPdz2/OVzk1TrynCbL5vjVlm6jb8Oeoj1tm7DBJ1z3x9+IjhervLrt67sQiQEBbsQCUHBLkRCULALkRAU7EIkhJbuxmezOYyNjgW1LRMb6TxHeLc4E2mtlI7suKfS/D3O6zxxJdfeFRayPMlhzZpwQggAvO+ee6jW0xlJuGjntete3heuy3fwEG/jtHrtBNWKkbZL6Q6+xn0HXwmOv3zwIJ3TObGdaqdP88c80M+1kVy4LlxnN6/jd2GKt8M6f+oQ1c6eCyfdAECxFknaIgUCJ2d4eL77/eE5VV62Tld2IZKCgl2IhKBgFyIhKNiFSAgKdiESgoJdiISwqPVmZuMAvoVGS2YH8JC7f83MvgjgjwGcbf7q5939p7H7qlaruHA23DLojn/ybjrv3e99b3C8rY0nHmQi9lqs/VM90gopjfDxKmXudxTKPGnl/MkjVLtQ5AkXF87xtkuHicV2+kw4AQkAukd4uyO0cVvRctx6K1fDySmP/+JXdM6GzTdTbXyQW5jtKf4y7iSJSKUir0F3OL+fat09vJZfzXkS1dTFOaoND08Exxcq/LX48188GxyfneX1FZfis1cB/Km7/87MegA8Z2aPN7Wvuvt/XcJ9CCFWmKX0epsEMNm8PWtmBwDwt1khxHXJ2/qb3cwmANwG4Jnm0GfNbK+ZPWxm/GtMQogVZ8nBbmbdAL4P4HPungfwdQCbAexE48r/ZTLvATPbY2Z7Zuf430lCiOVlScFuZlk0Av3b7v4DAHD3aXevuXsdwDcA7A7NdfeH3H2Xu+/q6ebVV4QQy8uiwW6NFinfBHDA3b9y2fjlGS0fA8BbugghVpyl7MbfBeBTAF4ysxeaY58H8Ekz24mGHXcUwJ8sdkeplKGLtK05ny/Sec/vfS44PjLCtwlGR4apVqlwW+vixRmqoRheY6bO72/tRm5rjQ/wTzqnDvI6aPNzvObayOjq4HjnUD+dk27ndtJCgT8vY2PrqTZ1Olw38Nz5cHsqABhbE2nLFWn1NVfi5x+Z8OutUud2aVsHyW4E0BbJpiyfP0s1pMJ15gBglGQdlku8hRk7HfwsLW03/lcAQo8w6qkLIa4v9A06IRKCgl2IhKBgFyIhKNiFSAgKdiESQksLTqYMaMuGM3lKxRk679e/fiI47hVuC/V28oKClQrPTioWeEupDHlv3DAxTufsuONGqm1ez225mRNh6woApi6eo1quI2w1bR4KW3IAcPYsz8i6edsOqt108zaqPfq/vhUczyBcABIAKvP8+SyXueaxKovt4ec61o5pYuMmqp058So/VopnYXZ08eNt3741OF5c4M/L+NhIcPwXOW7x6couREJQsAuREBTsQiQEBbsQCUHBLkRCULALkRBaar3V63UsFEgBxkgRyHs+9JHw/ZV5llQ6Yq/Va7yQn6e5fZLOhG2j9i5eeHFqhlt5szO879mFAl+/tfMikK++cDg4fv43PCNr00Zuob3rhi1UK0cy4jpyYavJIxmHsQy7VJq/VEmrNABAoU76BNb4+d2wjltvxbnzVLuxl2fLPfvc81Q7fSxs5xXm+evbFy4Gx8slnhGpK7sQCUHBLkRCULALkRAU7EIkBAW7EAlBwS5EQmht1lvK0NUdtq/6IpXyelaFs4JKEZuhPfI+ljOeeeUdPFuurTM8r17k2Umzs3mqpTt5oceRzf1U29zJs95eOxLu9QbjlmKWFAEFgFOTx6k2NMwLfjKtXOB2UqnEi1HORzLiSpHssEopbPVm2rldOrpmFdWOTU5Tbfo4OfcAinP8sb2+/4Xg+NAQX4cPDIbHI4U5dWUXIiEo2IVICAp2IRKCgl2IhKBgFyIhLLobb2btAJ4C0Nb8/b9y9y+Y2UYAjwIYAvAcgE+5O+9XA6BeL2JhliR/1Pn7Tta6g+PT03yH87WXj1KtPcN33HN9/VQbJu2m1gz30TmZSILPUN8Q1SK5OigWwkkQADAyEt7hX7smvHsLAJNTU1Q7ePAA1SbKG6nGnJLZWf6cLSzwne78Je5qxHbja+VwIlK6jSet7N/HW4fFWjKNjIxSbe0tvJbfyKrwvOFVvG5gO1n/E//wJJ2zlCt7CcAfuPutaLRnvtfM7gDw5wC+6u43ALgI4NNLuC8hxAqxaLB7gzfeOrPNfw7gDwD8VXP8EQAfXY4FCiGuDUvtz55udnA9A+BxAK8DmHH3N5KCTwJYuywrFEJcE5YU7O5ec/edANYB2A3gHUs9gJk9YGZ7zGzP7CwpXCGEWHbe1m68u88AeBLAnQD6zeyNDb51AE6ROQ+5+y5339XTw7+iKIRYXhYNdjNbZWb9zdsdAD4A4AAaQf9HzV+7H8CPlmmNQohrwFISYcYAPGJmaTTeHL7n7j82s5cBPGpm/xnA8wC+ueg91R110sYnFXnfyVTCSRy9pJUUADz39C+oNjXNE0ksy5NCdu9+Z3D87jt30TmXLnGrae/vnqHafJEnfhw8foJqh48eDY4XFvifUO68iFt7L0/GyOdnqTZLWlTN57ltGCklh0yaq32RT4xrNobtwYGhMTpnZA23vNbcdjPVBiM16HKx2oZMiyQvwcPxkoq0oFo02N19L4DbAuOH0fj7XQjxe4C+QSdEQlCwC5EQFOxCJAQFuxAJQcEuREKwWM2qa34ws7MAjjV/HAbAPbDWoXW8Ga3jzfy+rWODuwf90pYG+5sObLbH3blBrXVoHVrHNV2HPsYLkRAU7EIkhJUM9odW8NiXo3W8Ga3jzfyjWceK/c0uhGgt+hgvREJYkWA3s3vN7FUzO2RmD67EGprrOGpmL5nZC2a2p4XHfdjMzpjZvsvGBs3scTN7rfk/7620vOv4opmdap6TF8zswy1Yx7iZPWlmL5vZfjP7d83xlp6TyDpaek7MrN3MnjWzF5vr+E/N8Y1m9kwzbr5rFuljFsLdW/oPQBqNslabAOQAvAjgxlavo7mWowCGV+C47wFwO4B9l439FwAPNm8/CODPV2gdXwTwH1p8PsYA3N683QPgIIAbW31OIuto6TlBI9u3u3k7C+AZAHcA+B6ATzTH/weAf/N27nclruy7ARxy98PeKD39KID7VmAdK4a7PwXgwluG70OjcCfQogKeZB0tx90n3f13zduzaBRHWYsWn5PIOlqKN7jmRV5XItjXAri8+sJKFqt0AD8zs+fM7IEVWsMbjLr7ZPP2FABehHz5+ayZ7W1+zF/2Pycux8wm0Kif8AxW8Jy8ZR1Ai8/JchR5TfoG3d3ufjuADwH4jJm9Z6UXBDTe2dF4I1oJvg5gMxo9AiYBfLlVBzazbgDfB/A5d39TV4hWnpPAOlp+TvwqirwyViLYTwEYv+xnWqxyuXH3U83/zwD4IVa28s60mY0BQPP/MyuxCHefbr7Q6gC+gRadEzPLohFg33b3HzSHW35OQutYqXPSPPYM3maRV8ZKBPtvAWxp7izmAHwCwGOtXoSZdZlZzxu3AXwQwL74rGXlMTQKdwIrWMDzjeBq8jG04JyYmaFRw/CAu3/lMqml54Sto9XnZNmKvLZqh/Etu40fRmOn83UAf7ZCa9iEhhPwIoD9rVwHgO+g8XGwgsbfXp9Go2feEwBeA/B3AAZXaB1/CeAlAHvRCLaxFqzjbjQ+ou8F8ELz34dbfU4i62jpOQFwCxpFXPei8cbyHy97zT4L4BCA/wOg7e3cr75BJ0RCSPoGnRCJQcEuREJQsAuREBTsQiQEBbsQCUHBLkRCULALkRAU7EIkhP8HgqiJJe0C+/AAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[1], cmap='gray')\n",
    "class_names[int(y_train[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "## input layer  \n",
    "model.add(keras.layers.Flatten(input_shape=[32,32, 3]))\n",
    "\n",
    "## first and second hidden layers\n",
    "model.add(keras.layers.Dense(300, activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100, activation=\"relu\"))\n",
    "\n",
    "## output later (same as number of classes)\n",
    "model.add(keras.layers.Dense(10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 300)               307500    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 338,610\n",
      "Trainable params: 338,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hidden1 = model.layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = Hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03468666,  0.01520509, -0.00883617, ...,  0.01411853,\n",
       "         0.03896495,  0.05491541],\n",
       "       [-0.0587692 , -0.04887493, -0.02074859, ..., -0.01851254,\n",
       "        -0.01485252,  0.01122021],\n",
       "       [ 0.061928  , -0.01603653,  0.05964556, ...,  0.03476433,\n",
       "         0.00278488,  0.03145169],\n",
       "       ...,\n",
       "       [ 0.02213206,  0.04262713,  0.0322758 , ...,  0.01601781,\n",
       "         0.0036517 ,  0.05838753],\n",
       "       [-0.04753831,  0.05560283,  0.06101219, ..., -0.04332335,\n",
       "        -0.06579959,  0.00690479],\n",
       "       [-0.01927796, -0.00735502, -0.06256748, ..., -0.01153614,\n",
       "         0.06207931, -0.05187101]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    optimizer=\"sgd\", \n",
    "    metrics=[\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 95s 61ms/step - loss: 2.3027 - accuracy: 0.0987\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 94s 60ms/step - loss: 2.3027 - accuracy: 0.1004\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 94s 60ms/step - loss: 2.3027 - accuracy: 0.0970\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 93s 59ms/step - loss: 2.3027 - accuracy: 0.0981\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 98s 63ms/step - loss: 2.3027 - accuracy: 0.0973\n",
      "Epoch 6/30\n",
      " 710/1563 [============>.................] - ETA: 53s - loss: 2.3026 - accuracy: 0.0991"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ownert\\OneDrive\\Desktop\\Projects\\2022-Phase-3\\data-science\\skeleton-code\\sequential-neural-net.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X26sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "## change optimiser as the model's accuracy is not over 30% \n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\", \n",
    "    optimizer=\"adam\", \n",
    "    metrics=[\"accuracy\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 99s 63ms/step - loss: 2.3028 - accuracy: 0.1003\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 100s 64ms/step - loss: 2.3028 - accuracy: 0.0985\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 99s 63ms/step - loss: 2.3028 - accuracy: 0.0986\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 95s 61ms/step - loss: 2.3028 - accuracy: 0.1003\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 98s 62ms/step - loss: 2.3028 - accuracy: 0.0976\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer= keras.optimizers.SGD(learning_rate=0.01),\n",
    "    loss= keras.losses.MeanAbsoluteError(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 2/25\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 3/25\n",
      "1563/1563 [==============================] - 5s 3ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 4/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 5/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 6/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 7/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 8/25\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 9/25\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 10/25\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 11/25\n",
      "1563/1563 [==============================] - 7s 5ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 12/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 13/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 14/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 15/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 16/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 17/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 18/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 19/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 20/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 21/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 22/25\n",
      "1563/1563 [==============================] - 7s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 23/25\n",
      "1563/1563 [==============================] - 8s 5ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 24/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n",
      "Epoch 25/25\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 4s 13ms/step - loss: 2.3026 - accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3026344776153564, 0.10000000149011612]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577 - lr: 0.0100\n",
      "Epoch 2/15\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577 - lr: 0.0100\n",
      "Epoch 3/15\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577 - lr: 0.0100\n",
      "Epoch 4/15\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577 - lr: 0.0100\n",
      "Epoch 5/15\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577 - lr: 0.0100\n",
      "Epoch 6/15\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 4.4206 - accuracy: 0.9577\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
      "1563/1563 [==============================] - 6s 4ms/step - loss: 4.4200 - accuracy: 0.9577 - lr: 0.0100\n",
      "Epoch 6: early stopping\n"
     ]
    }
   ],
   "source": [
    "earlystopper = keras.callbacks.EarlyStopping(monitor='accuracy', patience=5, verbose=1)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='accuracy', factor=0.5, patience=5, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "\n",
    "history = model.fit(x = X_train,\n",
    "        y = y_train,\n",
    "        batch_size = 32,\n",
    "        epochs = 15,\n",
    "        verbose = 1,\n",
    "        callbacks=[earlystopper, reduce_lr],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 4.4200 - accuracy: 0.5178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4.4199981689453125, 0.517799973487854]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 30, 30, 32)        0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 28, 28, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 14, 14, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 7, 7, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 5, 5, 64)          73792     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1, 1, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 1, 1, 64)          0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 186,250\n",
      "Trainable params: 186,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model():\n",
    "        \"\"\"\n",
    "        Build CNN model and Perform the following operations:\n",
    "\n",
    "        1. Flatten the output of our base model to 1 dimension\n",
    "        2. Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "        3. This time, we will go with a dropout rate of 0.2\n",
    "        4. Add a final Fully Connected Sigmoid Layer\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        modelv2 = keras.models.Sequential()\n",
    "        modelv2.add(keras.layers.Conv2D(32,  kernel_size = 3,kernel_initializer='he_normal', activation='relu', input_shape = (32, 32, 3)))\n",
    "        # modelv2.add(keras.layers.normalization.BatchNormalization())\n",
    "        \n",
    "        modelv2.add(keras.layers.Dropout(0.2))\n",
    "        \n",
    "        modelv2.add(keras.layers.Conv2D(64, kernel_size = 3, kernel_initializer='he_normal', strides=1, activation='relu'))\n",
    "        # modelv2.add(keras.layers.normalization.BatchNormalization())\n",
    "        \n",
    "        modelv2.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "        modelv2.add(keras.layers.Conv2D(128, kernel_size = 3, strides=1, kernel_initializer='he_normal' ,padding='same', activation='relu'))\n",
    "        # modelv2.add(keras.layers.normalization.BatchNormalization())\n",
    "        \n",
    "        modelv2.add(keras.layers.MaxPooling2D((2, 2)))\n",
    "        modelv2.add(keras.layers.Conv2D(64, kernel_size = 3,kernel_initializer='he_normal', activation='relu'))\n",
    "        # modelv2.add(keras.layers.normalization.BatchNormalization())\n",
    "        \n",
    "        modelv2.add(keras.layers.MaxPooling2D((4, 4)))\n",
    "        modelv2.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "\n",
    "        modelv2.add(keras.layers.Flatten())\n",
    "        modelv2.add(keras.layers.Dense(256,kernel_initializer='he_normal', activation = \"relu\"))\n",
    "        modelv2.add(keras.layers.Dropout(0.1))\n",
    "        modelv2.add(keras.layers.Dense(10, kernel_initializer='glorot_uniform', activation = \"softmax\"))\n",
    "\n",
    "\n",
    "        # Compile the modelv2\n",
    "        modelv2.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])\n",
    "\n",
    "        \n",
    "        \n",
    "#         modelv2 = Sequential()\n",
    "#         modelv2.add(self.i_model)\n",
    "#         modelv2.add(GlobalAveragePooling2D())\n",
    "#         modelv2.add(Dense(128))\n",
    "#         modelv2.add(Dropout(0.1))\n",
    "#         modelv2.add(Dense(10, activation = 'softmax'))\n",
    "#         modelv2.compile(optimizer=SGD(lr=0.0001, momentum=0.99, decay=0.01), loss='categorical_crossentropy', metrics=['acc'])\n",
    "        return modelv2\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def train(model):\n",
    "        \"\"\"\n",
    "        Train the model with parameters:\n",
    "        epochs = 5\n",
    "        steps_per_epoch=100\n",
    "        validation_steps=50\n",
    "        \n",
    "        \"\"\"\n",
    "   \n",
    "        epochs=50\n",
    "#         steps_per_epoch=10\n",
    "#         validation_steps=5\n",
    "        \n",
    "            \n",
    "        # We'll stop training if no improvement after some epochs\n",
    "        earlystopper = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1)\n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=5, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "        # Save the best model during the traning\n",
    "#         checkpointer = ModelCheckpoint('best_model1.h5'\n",
    "#                                         ,monitor='val_acc'\n",
    "#                                         ,verbose=1\n",
    "#                                         ,save_best_only=True\n",
    "#                                         ,save_weights_only=True)\n",
    "        # Train\n",
    "        training = model.fit(x=X_train,\n",
    "                             y=y_train,\n",
    "                             batch_size=32,\n",
    "                             epochs=epochs,\n",
    "                             verbose=1,\n",
    "                             callbacks=[earlystopper, reduce_lr],                             \n",
    "                            )\n",
    "        \n",
    "        # Get the best saved weights\n",
    "#         model.load_weights('best_model1.h5')\n",
    "        return training\n",
    "\n",
    "    \n",
    "modelv2 = create_model()\n",
    "\n",
    "modelv2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 2.1003 - acc: 0.2096WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 93s 59ms/step - loss: 2.1003 - acc: 0.2096 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.9011 - acc: 0.2968WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 96s 61ms/step - loss: 1.9010 - acc: 0.2968 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.8296 - acc: 0.3246WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 99s 63ms/step - loss: 1.8295 - acc: 0.3246 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.7800 - acc: 0.3420WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 99s 63ms/step - loss: 1.7800 - acc: 0.3420 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.7341 - acc: 0.3594WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 99s 63ms/step - loss: 1.7341 - acc: 0.3594 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.6844 - acc: 0.3779WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 100s 64ms/step - loss: 1.6844 - acc: 0.3779 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.6428 - acc: 0.3917WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 100s 64ms/step - loss: 1.6427 - acc: 0.3917 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.6147 - acc: 0.4038WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 102s 65ms/step - loss: 1.6148 - acc: 0.4038 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.5943 - acc: 0.4156WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 100s 64ms/step - loss: 1.5944 - acc: 0.4155 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.5698 - acc: 0.4225WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 99s 63ms/step - loss: 1.5699 - acc: 0.4225 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.5583 - acc: 0.4280WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 100s 64ms/step - loss: 1.5584 - acc: 0.4279 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.5425 - acc: 0.4344WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 99s 63ms/step - loss: 1.5424 - acc: 0.4344 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.5219 - acc: 0.4441WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 101s 64ms/step - loss: 1.5220 - acc: 0.4441 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.5103 - acc: 0.4458WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 99s 63ms/step - loss: 1.5103 - acc: 0.4458 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.4977 - acc: 0.4538WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 99s 63ms/step - loss: 1.4977 - acc: 0.4538 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.4881 - acc: 0.4560WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 100s 64ms/step - loss: 1.4880 - acc: 0.4560 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.4749 - acc: 0.4632WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "1563/1563 [==============================] - 97s 62ms/step - loss: 1.4749 - acc: 0.4633 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "1414/1563 [==========================>...] - ETA: 9s - loss: 1.4669 - acc: 0.4642 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Ownert\\OneDrive\\Desktop\\Projects\\2022-Phase-3\\data-science\\skeleton-code\\sequential-neural-net.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m training\u001b[39m=\u001b[39mtrain(modelv2)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrained\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\Ownert\\OneDrive\\Desktop\\Projects\\2022-Phase-3\\data-science\\skeleton-code\\sequential-neural-net.ipynb Cell 29\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m         reduce_lr \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_acc\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m                                    verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m0.00001\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=73'>74</a>\u001b[0m         \u001b[39m# Save the best model during the traning\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m \u001b[39m#         checkpointer = ModelCheckpoint('best_model1.h5'\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m \u001b[39m#                                         ,monitor='val_acc'\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m \u001b[39m#                                         ,save_weights_only=True)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m         \u001b[39m# Train\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m         training \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(x\u001b[39m=\u001b[39;49mX_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m                              y\u001b[39m=\u001b[39;49my_train,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m                              batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m                              epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m                              verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m                              callbacks\u001b[39m=\u001b[39;49m[earlystopper, reduce_lr],                             \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=86'>87</a>\u001b[0m                             )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=88'>89</a>\u001b[0m         \u001b[39m# Get the best saved weights\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=89'>90</a>\u001b[0m \u001b[39m#         model.load_weights('best_model1.h5')\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Ownert/OneDrive/Desktop/Projects/2022-Phase-3/data-science/skeleton-code/sequential-neural-net.ipynb#X44sZmlsZQ%3D%3D?line=90'>91</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m training\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Ownert\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training=train(modelv2)\n",
    "print(\"Trained\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18b305c137df64328d0fde19fa393356681ff26b216faf0350a9c5bc90e3b26c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
